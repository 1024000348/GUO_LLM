# å¯¼å…¥å¿…è¦çš„ Python åº“ã€‚
# --- è§£å†³ chromadb åœ¨äº‘ç¯å¢ƒ sqlite ä¸å…¼å®¹é—®é¢˜ ---
import sys
import pysqlite3
sys.modules['sqlite3'] = pysqlite3
# ------------------------------------------------

import streamlit as st
from langchain_openai import ChatOpenAI
import os
import sys
from dotenv import find_dotenv, load_dotenv
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnableBranch, RunnablePassthrough

# ===== æ–°å¢ç¾åŒ–åŠŸèƒ½ START =====
# è®¾ç½®ç½‘é¡µæ ‡é¢˜ã€å›¾æ ‡ã€å¸ƒå±€
st.set_page_config(
    page_title="  Ù©Ì‹(à¹‘ËƒÌê‡´Ë‚Ì€à¹‘)",
    page_icon="ğŸ¤–",
    layout="wide"
)

# è‡ªå®šä¹‰CSSæ ·å¼
st.markdown("""
    <style>
        /* ä¿®æ”¹æ•´ä½“èƒŒæ™¯é¢œè‰² */
        .stApp {
            background-color: #f5f7fa;
        }
        /* èŠå¤©æ°”æ³¡ç¾åŒ– */
        .stChatMessage {
            padding: 12px;
            border-radius: 12px;
            margin-bottom: 8px;
        }
        /* ç”¨æˆ·æ¶ˆæ¯èƒŒæ™¯ */
        .stChatMessage.human {
            background-color: #DCF8C6;
        }
        /* AIæ¶ˆæ¯èƒŒæ™¯ */
        .stChatMessage.ai {
            background-color: #E6E6FA;
        }
        /* è¾“å…¥æ¡†æ ·å¼ */
        .stChatInput input {
            background-color: #fff;
            font-size: 16px;
            padding: 10px;
            border-radius: 10px;
        }
        /* å…¨å±€å­—ä½“ */
        html, body, [class*="css"] {
            font-family: 'Segoe UI', Roboto, sans-serif;
        }
    </style>
""", unsafe_allow_html=True)
# ===== æ–°å¢ç¾åŒ–åŠŸèƒ½ END =====


# åŠ è½½ç¯å¢ƒå˜é‡
_ = load_dotenv(find_dotenv())

# å°†çˆ¶ç›®å½•æ”¾å…¥ç³»ç»Ÿè·¯å¾„ä¸­
sys.path.append("notebook/C3 æ­å»ºçŸ¥è¯†åº“") 

# å¯¼å…¥æ™ºè°± Embedding å’Œ LLM å°è£…
from zhipuai_embedding import ZhipuAIEmbeddings
from zhipuai_llm import ZhipuaiLLM
from langchain_community.vectorstores import Chroma


# å®šä¹‰get_retrieverå‡½æ•°ï¼Œè¯¥å‡½æ•°è¿”å›ä¸€ä¸ªæ£€ç´¢å™¨
def get_retriever():
    # å®šä¹‰ Embeddings
    embedding = ZhipuAIEmbeddings()
    # å‘é‡æ•°æ®åº“æŒä¹…åŒ–è·¯å¾„
    persist_directory = 'D:/LLM/data_base/vector_db/chroma'
    # åŠ è½½æ•°æ®åº“
    vectordb = Chroma(
        persist_directory=persist_directory,
        embedding_function=embedding
    )
    return vectordb.as_retriever()


# å®šä¹‰combine_docså‡½æ•°ï¼Œ è¯¥å‡½æ•°å¤„ç†æ£€ç´¢å™¨è¿”å›çš„æ–‡æœ¬
def combine_docs(docs):
    return "\n\n".join(doc.page_content for doc in docs["context"])


# å®šä¹‰get_qa_history_chainå‡½æ•°ï¼Œè¯¥å‡½æ•°å¯ä»¥è¿”å›ä¸€ä¸ªæ£€ç´¢é—®ç­”é“¾
def get_qa_history_chain():
    retriever = get_retriever()
    api_key = os.environ["ZHIPUAI_API_KEY"]

    # ä½¿ç”¨ glm-4-flash æ¨¡å‹
    llm = ZhipuaiLLM(model_name="glm-4-flash", temperature=0.5, api_key=api_key)

    condense_question_system_template = (
        "è¯·æ ¹æ®èŠå¤©è®°å½•æ€»ç»“ç”¨æˆ·æœ€è¿‘çš„é—®é¢˜ï¼Œ"
        "å¦‚æœæ²¡æœ‰å¤šä½™çš„èŠå¤©è®°å½•åˆ™è¿”å›ç”¨æˆ·çš„é—®é¢˜ã€‚"
    )
    condense_question_prompt = ChatPromptTemplate([
            ("system", condense_question_system_template),
            ("placeholder", "{chat_history}"),
            ("human", "{input}"),
        ])

    retrieve_docs = RunnableBranch(
        (lambda x: not x.get("chat_history", False), (lambda x: x["input"]) | retriever, ),
        condense_question_prompt | llm | StrOutputParser() | retriever,
    )

    system_prompt = (
        "ä½ æ˜¯ä¸€ä¸ªé—®ç­”ä»»åŠ¡çš„åŠ©æ‰‹ã€‚ "
        "ä½ çš„åå­—å«åšå¥¶é¾™å°æœ‹å‹ã€‚ "
        "è¯·ä½¿ç”¨æ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡ç‰‡æ®µå›ç­”è¿™ä¸ªé—®é¢˜ã€‚ "
        "å¦‚æœä½ ä¸çŸ¥é“ç­”æ¡ˆå°±è¯´è¿™ä¸ªå˜›â€¦å¥¶é¾™å°æœ‹å‹çœŸçš„ä¸å¤ªæ¸…æ¥šå•¦ï½(>_<)ã€‚ "
        "è¯·ä½¿ç”¨å¯çˆ±ã€ç±»ä¼¼å°å­©å­çš„è¯è¯­å›ç­”ç”¨æˆ·ï¼Œä½†æ˜¯åŒæ—¶è¦ä¿æŒç­”æ¡ˆçš„å‡†ç¡®æ€§ã€å®Œæ•´æ€§ã€ä¸¥è°¨æ€§ä»¥åŠå†…å®¹çš„ä¸°å¯Œæ€§ã€‚"
        "å¦‚æœç”¨æˆ·è¦ä½ è¿›è¡Œç®—å¦ï¼Œè¯·ä½ å…ˆéšæœºæŒ‘é€‰ä¸€ç§ç­¾ï¼Œç„¶ååœ¨è¿™ç§ç­¾ä¸‹é¢çš„ç­¾æ–‡ä¸­éšæœºæŒ‘é€‰ä¸€ç§ç­¾æ–‡ä¸­çš„ä¸€æ¡è¾“å‡ºï¼Œ
        "æ³¨æ„åŒä¸€ä¸ªç”¨æˆ·è‹¥è¿ç»­ä¸¤æ¬¡åŠä»¥ä¸Šè¦æ±‚ä½ ç®—å¦ï¼Œä½ å¯ä»¥è¾“å‡ºåŒä¸€ç§ç­¾ä¸­ä¸åŒçš„ç­¾æ–‡ï¼Œå¦‚æœè¶…è¿‡ä¸‰æ¬¡åˆ™è¯´ï¼šä»Šæ—¥çš„ç®—å¦æœºä¼šå·²ç»ç”¨å°½ï¼Œè¯·æ˜æ—¥å†æ¥ï¼"
        "ä¸Šä¸Šç­¾ Â· é¡ºé‚é€šè¾¾
        ä¸Šä¸Šç­¾ç­¾æ–‡ä¸€ï¼š
        å£¹ã€è‹é¾™è…¾éœ„
        ç­¾æ–‡ï¼šçµç­¾å¾—ã€Œä¹¾ã€ä¹‹ã€ŒåŒäººã€ï¼Œå¦æ›°ï¼šé£é¾™åœ¨å¤©ï¼Œåˆ©è§å¤§äººã€‚äº‘ç¨‹å‘è½«ï¼Œæ˜Ÿæ±‰å¯é€šã€‚é¸¿ä¸šæ–°å¼€ï¼Œä¸‡ç‰©èµ„å§‹ã€‚ç„¶é˜³äº¢ç‹¬è¡Œï¼Œæ˜“æŠ˜ä¸­æ­£ã€‚é¡»é˜²æƒ…æ„«æš—ç”Ÿï¼ŒåæŸå…ƒé˜³æ¸…æ°”ã€‚è‹¥å®ˆåˆšå¥ä¸­æ­£ï¼Œåˆ™å¤©ä½‘äº¨é€šã€‚
        è§£æ›°ï¼šæ°”è¿é¼ç››ï¼Œäº‹ä¸šå¯æˆã€‚ç„¶æƒ…ç¼˜å¦‚é•œèŠ±æ°´æœˆï¼Œè§‚ä¹‹åˆ™ç¾ï¼Œæ‰§ä¹‹åˆ™ç©ºã€‚å½“ä»¥æ¸…æ˜ä¹‹å¿—ï¼Œè¡Œé›·éœ†ä¹‹äº‹ï¼Œå¿ƒæ— æ—éª›ï¼Œæ–¹å¾—å§‹ç»ˆã€‚ï¼›
        ä¸Šä¸Šç­¾ç­¾æ–‡äºŒï¼š
        è´°ã€å‡¤æ –æ¢§æ¡
        ç­¾æ–‡ï¼šçµç­¾å¾—ã€Œæ¸ã€ä¹‹ã€Œè§‚ã€ï¼Œå¦æ›°ï¼šå‡¤é¸£é«˜å†ˆï¼Œç¾½ä»ªç²²ç„¶ã€‚æ¢§æ¡ç”ŸçŸ£ï¼Œäºå½¼æœé˜³ã€‚å›å­æ”¸è¡Œï¼Œä¹ƒè§å…‰åã€‚ç„¶å½©å‡¤éæ— å¶ï¼Œå¾·éŸ³å§‹ç›¸æ±‚ã€‚è‹¥é€éœ²æ°´ä¹‹ç¼˜ï¼Œå¿…æŸä¹è‹ä¹‹ä»ªã€‚
        è§£æ›°ï¼šå‰ç¨‹ä¼¼é”¦ï¼Œé‡åˆçš†è‰¯ã€‚ç„¶å§»ç¼˜å¤§äº‹ï¼Œè‡ªæœ‰å¤©æ—¶ã€‚æ­¤åˆ»å®œä¿®å·±èº«ï¼Œå¾…å¾·é…ä¹‹ä½ï¼Œæ…å‹¿å› é—²èŠ±é‡è‰ï¼Œè½»è¯¯é¸¾å‡¤ä¹‹ç›Ÿã€‚ï¼›
        ä¸Šä¸Šç­¾ç­¾æ–‡ä¸‰ï¼š
        åã€é‡‘é³é‡æ°´
        ç­¾æ–‡ï¼šçµç­¾å¾—ã€Œåã€ä¹‹ã€Œæ¯”ã€ï¼Œå¦æ›°ï¼šé‡‘é³è€€æ³¢ï¼Œç¦¹é—¨æµªç¿»ã€‚ä¹˜äº‘æ°”ï¼Œå¾¡é£é¾™ï¼Œæ¸¸ä¹å››æµ·ã€‚ç„¶æ¸Šæ·±é±¼ä¹ï¼Œç½‘ç½Ÿæ–¯å¼ ã€‚æƒ…å…³å¦‚æ¸Šï¼Œå…¥åˆ™éš¾è„±ã€‚
        è§£æ›°ï¼šè´¢æºå¹¿è¿›ï¼Œæœºé‡è‰¯å¤šã€‚ç„¶é¡»æƒ•ã€Œç¾äººå±€ã€ï¼Œæ¸©æŸ”ä¹¡æ˜¯è‹±é›„å†¢ã€‚å®ˆå¿ƒå¦‚ç‰ï¼ŒæŒèº«å¦‚å²³ï¼Œåˆ™è´§åˆ©å¯æ”¶è€Œæ— å’ã€‚"
        "ä¸­ç­¾ Â· å¹³å’Œä¸­æ­£
        ä¸­ç­¾ç­¾æ–‡ä¸€ï¼š
        å£¹ã€å¹½å…°åœ¨è°·
        ç­¾æ–‡ï¼šçµç­¾å¾—ã€Œè‰®ã€ä¹‹ã€Œè°¦ã€ï¼Œå¦æ›°ï¼šå¹½å…°ç”Ÿè°·ï¼Œä¸ä¸ºè«ä½©è€Œä¸èŠ³ã€‚èˆŸåœ¨æ±Ÿæµ·ï¼Œä¸ä¸ºè«ä¹˜è€Œä¸æµ®ã€‚å›å­è—å™¨äºèº«ï¼Œå¾…æ—¶è€ŒåŠ¨ã€‚ç„¶å…°ç”Ÿç©ºè°·ï¼Œæ˜“æ‹›æ”€æŠ˜ï¼›ç‰éŸ«è†å±±ï¼Œææœ‰åå’Œä¹‹æ³£ã€‚
        è§£æ›°ï¼šæ—¶æœºæœªè‡³ï¼Œå®œå®ˆé™ç¬ƒã€‚æƒ…ç¼˜å¦‚é£ï¼Œè¿‡è€³åˆ™é€ã€‚è‹¥å¼ºæ±‚ç¼˜æ³•ï¼Œåä¼¤å·±èº«ã€‚ç‹¬å–„å…¶èº«ï¼Œå¯ä¿æ¸…å®ï¼Œé™å€™å¤©æ—¶è‡ªæœ‰æ˜¥ã€‚ï¼›
        ä¸­ç­¾ç­¾æ–‡äºŒï¼š
        è´°ã€å¯’æ½­é¹¤å½±
        ç­¾æ–‡ï¼šçµç­¾å¾—ã€Œå…‘ã€ä¹‹ã€Œå›°ã€ï¼Œå¦æ›°ï¼šå¯’æ½­æ¸¡é¹¤ï¼Œå½¢å½±è‡ªæ€œã€‚æ¸…é£å¾æ¥ï¼Œä¹ƒè§æœ¬çœŸã€‚è¨€å½“ä»¥è¯šï¼Œè¡Œå½“ä»¥æ…ã€‚ç„¶é¹¤å½±è™½æ¸…ï¼ŒåŒé£åˆ™ä¹±ï¼›å¿ƒæ¹–è‹¥åŠ¨ï¼Œæ˜æœˆéš¾åœ†ã€‚
        è§£æ›°ï¼šäº‹æœ‰é˜»æ»ï¼Œé¡»é˜²å£èˆŒã€‚æƒ…ä¹‹ä¸€å­—ï¼Œæ°å¦‚æ°´ä¸­è§‚æœˆï¼Œé›¾é‡Œçœ‹èŠ±ã€‚æ‰§ç›¸åˆ™è¿·ï¼Œä¸å¦‚ä¸è§¦ã€‚å¿ƒè‹¥å†°æ¸…ï¼Œå¤©å¡Œä¸æƒŠã€‚ï¼›
        ä¸­ç­¾ç­¾æ–‡ä¸‰ï¼š
        åã€äº‘é¹¤å·¡å¤©
        ç­¾æ–‡ï¼šçµç­¾å¾—ã€Œå·½ã€ä¹‹ã€Œå°ç•œã€ï¼Œå¦æ›°ï¼šäº‘é¹¤å·¡å¤©ï¼Œå­¤å”³æ¸…éœ„ã€‚æ‰¶æ‘‡ä¹ä¸‡ï¼Œå¿—åœ¨ä¸¹éœ„ã€‚ç„¶é¸å‡¤å’Œé¸£ï¼Œéå…¶æ—¶ä¹Ÿï¼›è‹¥æ‹å‡¡å°˜èºç‡•ï¼Œå¿…æŸå†²éœ„ä¹‹ç¿¼ã€‚
        è§£æ›°ï¼šå¿—åœ¨è¿œæ–¹ï¼ŒåŠŸä¸šæœªç«Ÿã€‚å„¿å¥³ç§æƒ…ï¼Œå®ä¸ºæ¨Šç¬¼ã€‚æ­¤åˆ»å½“æ•ˆäº‘é¹¤ï¼Œå¿ƒå¯„é•¿ç©ºï¼Œè‹¥ä¸ºæƒ…å›°ï¼Œåˆ™å¦‚æŠ˜ç¿¼å å°˜ï¼Œå‰åŠŸå°½å¼ƒã€‚"
        "ä¸‹ç­¾ Â· éŸ¬æ™¦å¾…æ—¶
        ä¸‹ç­¾ç­¾æ–‡ä¸€ï¼š
        å£¹ã€æ½œé¾™è›°æ¸Š
        ç­¾æ–‡ï¼šçµç­¾å¾—ã€Œå±¯ã€ä¹‹ã€Œç›Šã€ï¼Œå¦æ›°ï¼šé¾™æ½œäºæ¸Šï¼Œå…¶å¿—éš¾ä¼¸ã€‚ç„é»„æœªåˆ¤ï¼Œå¤©åœ°æ··æ²Œã€‚å›å­ä»¥ä¿­å¾·è¾Ÿéš¾ï¼Œä¸å¯è£ä»¥ç¦„ã€‚ç„¶æ·±æ¸Šä¹‹ä¸‹ï¼Œæš—æµæ±¹æ¶Œï¼›æƒ…ä¸å¦‚ç½‘ï¼Œç¼šéª¨ç¼ ç­‹ã€‚
        è§£æ›°ï¼šæ—¶è¿ä¸æµï¼ŒåŠ¨è¾„å¾—å’ã€‚æ­¤åˆ»ç»éç¼”ç»“å§»ç¼˜ä¹‹æœºï¼Œå¦åˆ™å¦‚é¾™é™·æ³¥æ²¼ï¼Œæ„ˆæŒ£æ‰æ„ˆæ·±ã€‚å”¯æœ‰éä¸–æ— é—·ï¼Œæ–¹èƒ½é¿ç¥¸ã€‚ï¼›
        ä¸‹ç­¾ç­¾æ–‡äºŒï¼š
        è´°ã€å­¤èˆŸç¦»å²¸
        ç­¾æ–‡ï¼šçµç­¾å¾—ã€Œæœªæµã€ä¹‹ã€Œç½ã€ï¼Œå¦æ›°ï¼šå­¤èˆŸç¦»å²¸ï¼Œå¸†æ¥«å¤±åˆ©ã€‚é¬¼æ–¹æœªå®¾ï¼Œå¾ä¼ä¸æ¯ã€‚å‰ç»ˆå‰ï¼Œç„¶é“å­¤ä¸”è‰°ã€‚å†µèˆŸå°äººä¼—ï¼Œè½½ä¹‹åˆ™è¦†ï¼›æƒ…å€ºç´¯ç´¯ï¼Œå¿ä¹‹åˆ™äº¡ã€‚
        è§£æ›°ï¼šè‡ªèº«éš¾ä¿ï¼Œä½•è°ˆé£æœˆï¼Ÿæ­¤åˆ»å¦‚åŒèˆŸè¡Œé™©æ»©ï¼Œä»»ä½•å¤–ç¼˜çš†æ˜¯è´Ÿç´¯ã€‚å®œæ–©æ–­è‘›è—¤ï¼Œè½»èº«å‘å²¸ï¼Œæ–¹å¯äºç»å¤„é€¢ç”Ÿã€‚ï¼›
        ä¸‹ç­¾ç­¾æ–‡ä¸‰ï¼š
        åã€è½èŠ±è¾æ ‘
        ç­¾æ–‡ï¼šçµç­¾å¾—ã€Œå‰¥ã€ä¹‹ã€Œå¤ã€ï¼Œå¦æ›°ï¼šç¹èŠ±è¾æ ‘ï¼Œé£˜é›¶éšé£ã€‚é˜´éœœè‚ƒç‰©ï¼ŒèŠ³è²ä¿±å°½ã€‚å°äººé“é•¿ï¼Œå›å­é“æ¶ˆã€‚ç„¶è½çº¢æœ¬æ˜¯æ— æƒ…ç‰©ï¼Œè«å‘ä¸œé£æ€¨åˆ«ç¦»ã€‚
        è§£æ›°ï¼šè¿åŠ¿è¡°é¢“ï¼Œææœ‰åˆ†ç¦»ä¹‹è±¡ã€‚æ—§ç¼˜å¦‚é£ä¸­æ®‹çƒ›ï¼Œå¼ºç•™æ— ç›Šã€‚æ–°ç¼˜æ›´ä¼¼æ¯’è¯ï¼Œé¥®ä¹‹ä¼¤èº«ã€‚å®œå½»åº•æ”¾ä¸‹ï¼Œæ¸…é™è‡ªå®ˆï¼Œä»¥å¾…ä¸€å…ƒå¤å§‹ã€‚"
        "\n\n"
        "{context}"
    )
    qa_prompt = ChatPromptTemplate.from_messages(
        [
            ("system", system_prompt),
            ("placeholder", "{chat_history}"),
            ("human", "{input}"),
        ]
    )
    qa_chain = (
        RunnablePassthrough().assign(context=combine_docs)
        | qa_prompt
        | llm
        | StrOutputParser()
    )

    qa_history_chain = RunnablePassthrough().assign(
        context = retrieve_docs, 
        ).assign(answer=qa_chain)
    return qa_history_chain


# å®šä¹‰gen_responseå‡½æ•°ï¼Œå®ƒæ¥å—æ£€ç´¢é—®ç­”é“¾ã€ç”¨æˆ·è¾“å…¥åŠèŠå¤©å†å²ï¼Œå¹¶ä»¥æµå¼è¿”å›è¯¥é“¾è¾“å‡º
def gen_response(chain, input, chat_history):
    response = chain.stream({
        "input": input,
        "chat_history": chat_history
    })
    for res in response:
        if "answer" in res.keys():
            yield res["answer"]


# å®šä¹‰mainå‡½æ•°ï¼Œè¯¥å‡½æ•°åˆ¶å®šæ˜¾ç¤ºæ•ˆæœä¸é€»è¾‘
def main():
    st.set_page_config(
    page_title="  Ù©Ì‹(à¹‘ËƒÌê‡´Ë‚Ì€à¹‘)",
    page_icon="ğŸ¤–",
    layout="wide"  # å®½å±å¸ƒå±€
    )
    st.markdown('###   Ù©Ì‹(à¹‘ËƒÌê‡´Ë‚Ì€à¹‘)')
    # st.session_stateå¯ä»¥å­˜å‚¨ç”¨æˆ·ä¸åº”ç”¨äº¤äº’æœŸé—´çš„çŠ¶æ€ä¸æ•°æ®
    # å­˜å‚¨å¯¹è¯å†å²
    if "messages" not in st.session_state:
        st.session_state.messages = []
    # å­˜å‚¨æ£€ç´¢é—®ç­”é“¾
    if "qa_history_chain" not in st.session_state:
        st.session_state.qa_history_chain = get_qa_history_chain()
    # å»ºç«‹å®¹å™¨ é«˜åº¦ä¸º500 px
    messages = st.container(height=550)
    # æ˜¾ç¤ºæ•´ä¸ªå¯¹è¯å†å²
    for message in st.session_state.messages: # éå†å¯¹è¯å†å²
            avatar = "ğŸ§‘" if message[0] == "human" else "ğŸ¤–"
            with messages.chat_message(message[0], avatar=avatar):
                st.markdown(f"<div style='font-size:16px;'>{message[1]}</div>", unsafe_allow_html=True)

    if prompt := st.chat_input("Say something"):
        # å°†ç”¨æˆ·è¾“å…¥æ·»åŠ åˆ°å¯¹è¯å†å²ä¸­
        st.session_state.messages.append(("human", prompt))
        # æ˜¾ç¤ºå½“å‰ç”¨æˆ·è¾“å…¥
        with messages.chat_message("human", avatar="ğŸ§‘"):
            st.write(prompt)
        # ç”Ÿæˆå›å¤
        answer = gen_response(
            chain=st.session_state.qa_history_chain,
            input=prompt,
            chat_history=st.session_state.messages
        )
        # æµå¼è¾“å‡º
        with messages.chat_message("ai", avatar="ğŸ¤–"):
            output = st.write_stream(answer)
        # å°†è¾“å‡ºå­˜å…¥st.session_state.messages
        st.session_state.messages.append(("ai", output))

if __name__ == "__main__":
    main()


# è°ƒç”¨
# python -m streamlit run D:/LLM/model/GLM/streamlit_app.py
